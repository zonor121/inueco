# Практическое задание: Подготовка и очистка медицинского датасета

## Цель задания

Научиться проводить полный цикл очистки и подготовки реального медицинского датасета для последующего использования в машинном обучении. Вы отработаете обработку пропусков, выбросов, категориальных переменных и масштабирование данных.

<https://www.kaggle.com/datasets/fedesoriano/stroke-prediction-dataset>

## Задание (шаги)

**Часть 1: Загрузка и первичный анализ данных**

1. Загрузите датасет `healthcare-dataset-stroke-data.csv`
2. Проверьте структуру данных: размер, типы столбцов
3. Проведите описательный статистический анализ
4. Определите баланс классов целевой переменной `stroke`

**Часть 2: Обработка пропущенных значений**
5. Найдите все пропущенные значения в датасете
6. Для столбца `bmi` замените пропуски медианным значением
7. Проверьте, остались ли другие столбцы с пропусками

**Часть 3: Работа с категориальными переменными**
8. Приведите категориальные переменные к единому формату (устраните опечатки, приведите к нижнему регистру)
9. Обработайте редкие категории в столбце `gender` (категория "Other" встречается 1 раз)
10. Проверьте столбец `smoking_status` на наличие нестандартных значений

**Часть 4: Обработка выбросов**
11. Определите выбросы в числовых столбцах `age`, `avg_glucose_level`, `bmi` (например, используя межквартильный размах)
12. Для `avg_glucose_level` и `bmi` ограничьте выбросы с помощью метода Winsorization (замените на 1-й и 99-й процентили)
13. Проверьте, остались ли аномальные значения в `age` (например, возраст > 120 лет)

**Часть 5: Нормализация и кодирование**
14. Примените `StandardScaler` к числовым признакам: `age`, `avg_glucose_level`, `bmi`
15. Закодируйте категориальные переменные методом One-Hot Encoding, кроме:
    - `gender` (используйте LabelEncoding: Male=0, Female=1)
    - `ever_married` (LabelEncoding: No=0, Yes=1)
    - `Residence_type` (LabelEncoding: Rural=0, Urban=1)
16. Удалите ненужные столбцы: `id`

**Часть 6: Валидация и сохранение**
17. Проверьте, что после обработки нет пропущенных значений
18. Проверьте баланс классов (возможно, применить технику ресемплинга)
19. Сохраните очищенный датасет в формате CSV
20. Визуализируйте тепловую карту корреляций между признаками

## Подсказки по ключевым частям кода

```python
# Пример обработки пропусков в столбце bmi
median_bmi = df['bmi'].median()
df['bmi'] = df['bmi'].fillna(median_bmi)

# Обработка выбросов методом Winsorization
from scipy.stats.mstats import winsorize
df['avg_glucose_level'] = winsorize(df['avg_glucose_level'], limits=[0.01, 0.01])

# Обработка редкой категории в gender
df['gender'] = df['gender'].replace('Other', df['gender'].mode()[0])

# LabelEncoding для бинарных категорий
from sklearn.preprocessing import LabelEncoder
le = LabelEncoder()
df['gender_encoded'] = le.fit_transform(df['gender'])

# Масштабирование числовых признаков
from sklearn.preprocessing import StandardScaler
scaler = StandardScaler()
numeric_cols = ['age', 'avg_glucose_level', 'bmi']
df[numeric_cols] = scaler.fit_transform(df[numeric_cols])
```

## Чек-лист перед отправкой работы

1. [ ] Все пропущенные значения обработаны (особенно в столбце `bmi`)
2. [ ] Категориальные переменные приведены к единому формату
3. [ ] Редкая категория "Other" в поле `gender` обработана
4. [ ] Выбросы в `avg_glucose_level` и `bmi` ограничены
5. [ ] Возраст пациента в разумных пределах (нет значений > 120)
6. [ ] Числовые признаки нормализованы с помощью StandardScaler
7. [ ] Категориальные признаки правильно закодированы
8. [ ] Столбец `id` удален из финального датасета
9. [ ] Целевая переменная `stroke` сохранена без изменений
10. [ ] Создана тепловая карта корреляций
11. [ ] Очищенный датасет сохранен в CSV-формате
12. [ ] Код содержит комментарии к ключевым шагам

## Советы по улучшению работы

1. **Документация**: Добавьте docstring к каждой функции и комментарии к сложным операциям
2. **Визуализация**: Создайте графики распределения признаков до и после очистки
3. **Модульность**: Разделите код на логические функции (load_data, clean_data, etc.)
4. **Воспроизводимость**: Используйте random seed для всех стохастических операций
5. **Анализ дисбаланса**: Рассмотрите применение SMOTE для балансировки классов, если дисбаланс значительный
6. **Валидация**: Разделите данные на train/test до любых операций, связанных с целевой переменной
7. **Логирование**: Добавьте вывод промежуточных результатов (количество пропусков, выбросов и т.д.)
8. **Оптимизация**: Для больших датасетов используйте vectorized operations вместо циклов

## Пример структуры финального кода

```python
import pandas as pd
import numpy as np
from sklearn.preprocessing import StandardScaler, LabelEncoder
from scipy.stats.mstats import winsorize
import matplotlib.pyplot as plt
import seaborn as sns

def load_and_explore_data(filepath):
    """Загрузка и первичный анализ данных"""

def clean_data(df):
    """Основная функция очистки данных"""
    # 1. Обработка пропусков

    # 2. Обработка категориальных переменных

    # 3. Обработка выбросов

    # 4. Нормализация и кодирование

    # 5. Удаление ненужных столбцов

    return df

# Основной блок выполнения
if __name__ == "__main__":
    # Загрузка данных

    # Очистка данных

    # Визуализация

    # Сохранение
```

